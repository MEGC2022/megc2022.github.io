<!DOCTYPE HTML>
<!--
	TXT by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>ACMMM MEGC2022</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<div class="logo container">
						<div>
							<h1><a href="index.html" id="logo">ACMMM MEGC2022 </a></h1>
							<p>Facial Micro-Expression Grand Challenge 2022</p>
						</div>
					</div>
				</header>

			<!-- Nav -->
				<nav id="nav">
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="callforpaper.html">Call for Papers</a>
						<li
							class="current"><a href="challenge.html">Challenge</a>
							<ul>
								<li><a href="challenge.html#genenration">Generations task</a></li>
								<li><a href="challenge.html#spotting">Spotting task</a></li>
								<li><a href="challenge.html#questions">Frequently Asked Questions</a></li>
							</ul>
						</li>
						<li><a href="submission.html">Submission</a></li>
						<li><a href="organisers.html">Organisers</a></li>
						<li><a href="program.html">Program</a></li>
						<li><a href="review.html">Continuity</a></li>
					</ul>
				</nav>

			<!-- Main -->
				<section id="main">
					<div class="container">

							<!-- Content -->
							<section>

								<header class="main">
									<h2 class="major"><span>ME generation taks</span></h2>
								</header>
								<a name="generation"></a>

								<!--<h2> - Advanced techniques for Facial Expressions Generation and Spotting</h2> -->
								<h3>Recommended Training Databases</h3>
								<uL>
									<LI> <b>SAMM with 159 MEs at 200fps.</b></Li>
									<uL><li> To download the dataset, please visit: <a href="http://www2.docm.mmu.ac.uk/STAFF/M.Yap/dataset.php"></a>http://www2.docm.mmu.ac.uk/STAFF/M.Yap/dataset.php. Download and fill in the license agreement form, email to <a href="M.Yap@mmu.ac.uk"></a>M.Yap@mmu.ac.uk with email subject: SAMM.</li>
										<li>
											Reference: Davison, A. K., Lansley, C., Costen, N., Tan, K., & Yap, M. H. (2016). SAMM: A spontaneous micro-facial movement dataset. IEEE transactions on affective computing, 9(1), 116-129.
										</li>
									</uL>


								<LI> <b>CASME II with 247 FMEs at 200 fps.</b></Li>
								<uL><li> To download the dataset, please visit: <a href="http://fu.psych.ac.cn/CASME/casme2-en.php"></a>http://fu.psych.ac.cn/CASME/casme2-en.php. Download and fill in the license agreement form, upload the file through this link: <a href="https://www.wjx.top/vj/hSaLoan.aspx"></a>https://www.wjx.top/vj/hSaLoan.aspx.</li>
									<li>
										Reference:
									</li>
								</uL>

								<LI> <b>SMIC: SMIC-VIS and SMIC-NIR with 71 MEs at 25fps, SMIC-HS with 164 MEs at 100fps.</b>
								<uL><li> To download the dataset, please visit: <a href="https://www.oulu.fi/cmvs/node/41319"></a>https://www.oulu.fi/cmvs/node/41319. Download and fill in the license agreement form (please indicate which version/subset you need), email to <a href="Xiaobai.Li@oulu.fi"></a>Xiaobai.Li@oulu.fi.</li>
									<li>
										Reference: Li, X., Pfister, T., Huang, X., Zhao, G., & Pietik√§inen, M. (2013, April). A spontaneous micro-expression database: Inducement, collection and baseline. In 2013 10th IEEE International Conference and Workshops on Automatic face and gesture recognition (fg) (pp. 1-6). IEEE.
									</li>
								</uL>
								</uL>
								<p> </p>
								<h3>Template faces and Designated micro-expressions for generation</h3>
								<LI> <b>Available soon</b>

							<p> </p>
							<h3>Evaluation Protocol</h3>
								<LI>The three experts who are FACS AU coders will evaluate the results without interfering with each other.
								<LI>Guidelines: Available soon

							</section>
						<section>
							<header class="main">
									<h2 class="major"><span>ME and Macro-expression Spotting taks</span></h2>
								</header>
								<a name="spotting"></a>
							<h3>Recommended Training Databases</h3>
							<uL>
								<LI> <b>SAMM Long Videos with 147 long videos at 200 fps (average duration: 35.5s).</b>
							<uL><li> To download the dataset, please visit: <a href="http://www2.docm.mmu.ac.uk/STAFF/M.Yap/dataset.php"></a>http://www2.docm.mmu.ac.uk/STAFF/M.Yap/dataset.php. Download and fill in the license agreement form, email to <a href="M.Yap@mmu.ac.uk"></a>M.Yap@mmu.ac.uk with email subject: SAMM long videos. </li>
							<li>
											Reference: Yap, C. H., Kendrick, C., & Yap, M. H. (2020, November). SAMM long videos: A spontaneous facial micro-and macro-expressions dataset. In 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020) (pp. 771-776). IEEE.
										</li>
							</uL>

								<LI><b> CAS(ME)<sup>2</sup> with 97 long videos at 30 fps (average duration: 148s).</b>
							<uL><li> To download the dataset, please visit: <a href="http://fu.psych.ac.cn/CASME/casme2-en.php"></a>http://fu.psych.ac.cn/CASME/casme2-en.php. Download and fill in the license agreement form, upload the file through this link: <a href="https://www.wjx.top/vj/QR147Sq.aspx"></a>https://www.wjx.top/vj/QR147Sq.aspx.</li>
								<li>
											Reference: Qu, F., Wang, S. J., Yan, W. J., Li, H., Wu, S., & Fu, X. (2017). CAS (ME) $^ 2$: a database for spontaneous macro-expression and micro-expression spotting and recognition. IEEE Transactions on Affective Computing, 9(4), 424-436.
										</li>

							</uL>

								<LI> <b>SMIC-E-long with 162 long videos at 100 fps (average duration: 22s).</b>
							<uL><li> To download the dataset, please visit: <a href="https://www.oulu.fi/cmvs/node/41319"></a>https://www.oulu.fi/cmvs/node/41319. Download and fill in the license agreement form (please indicate which version/subset you need), email to <a href="Xiaobai.Li@oulu.fi"></a>Xiaobai.Li@oulu.fi.</li>
								<li>
											Reference: Tran, T. K., Vo, Q. N., Hong, X., Li, X., & Zhao, G. (2021). Micro-expression spotting: A new benchmark. Neurocomputing, 443, 356-368.
										</li>
							</uL>
								</uL>
							<p> </p>

							<h3>Unseen Test Dataset</h3>
							<LI> <b>Release in Mid-May</b>

							<p> </p>
							<h3>Evaluation Protocol</h3>
							<uL>
							<Li> Baseline Method:<br />
									Please cite:
									<br />
Yap, C.H., Yap, M.H., Davison, A.K., Cunningham, R. (2021), Efficient Lightweight 3D-CNN using Frame Skipping and Contrast Enhancement for Facial Macro- and Micro-expression Spotting, arXiv:2105.06340 [cs.CV], <a href="https://arxiv.org/abs/2105.06340">https://arxiv.org/abs/2105.06340</a>.
							<Li> Baseline result:  Available soon

							<Li> The <b>Leaderboards</b> will be available at Mid-May.

								<Li> <b>Validation stage</b>: Mid May - Early June (The specific date will be determined soon. )
							<ul>
								<li> The participants could upload the result (csv) and then the Leaderboards will calculate the metrics and display the ranking.
								</li>
							</ul>
								<Li> <b>Test stage</b>: Mid May - Early June (The specific date will be determined soon. )
								<ul>
								<li> The participants could upload the result (csv). The interface will calculate and display only the participant's own results.
								</li>
									</ul>
								<Li> Detailed description of metrics and the csv format will be available soon.
						</Li>
</uL>





						</section>
						<section>
								<h2 class="major"><span>Frequently Asked Questions</span></h2>
								<a name="questions"></a>
								<OL>
									<li>Q: How to deal with the spotted intervals with overlap? <br />
												A: We consider that each ground-truth interval corresponds to at most one single spotted interval. If your algorithm detects multiple  with overlap, you should merge them into an optimal interval. The fusion method is also part of your algorithm, and the final result evaluation only cares about the optimal interval obtained.
									</li>


								</OL>


								<br />
						</section>




					</div>
				</section>
				<footer id="footer">
				<!-- Copyright -->
							<div id="copyright">
								<ul class="menu">
									<li>GET IN TOUCH: lijt@psych.ac.cn</li>
									<li>&copy; MEGC2022. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
								</ul>
							</div>

				</footer>



			</div>

		<!-- Scripts -->
			<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
